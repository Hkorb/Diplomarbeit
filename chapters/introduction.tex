% !TEX root = ../Diploma.tex

While human made climate change only begins to effect the countries of Europe and North America, the predictions for the near and far future are devastating \cite{hoegh-guldberg_impacts_2019}. Electricity production accounts for up to a third of greenhouse gas emissions in major industrial countries like the United States \cite{hockstad_inventory_2018} and Germany \cite{ortl_entwicklung_2020}. Therefore, the energy sector is shifting to renewable sources of energy such as wind and solar energy \cite{international_energy_agency_global_2020}.\\
To reduce investment and maintenance costs, wind turbines are often arranged in wind farms of multiple, sometimes hundreds of turbines. However, this also reduces the overall efficiency of the turbines due to wake losses \cite{nilsson_large-eddy_2015}. One approach to mitigate these losses is to control the turbines in a way, that reduce wake interaction, for example by curtailing the upstream turbines. This was first studied by Steinbuch et al. \cite{steinbuch_optimal_1988}. Multiple studies since then have tested this strategy and a recent survey of them found that a static curtailment does not significantly increase the overall power production, when tested with high fidelity simulations \cite{kheirabadi_quantitative_2019}. However, the exploration of dynamic approaches has also begun. Goit and Munters used receding horizon optimal control to prove that an increase of $16$ percent is possible \cite{goit_optimal_2015}. Based on these results, Munters and Meyers proposed a sinusoidal variation of $C_P$ and also found increased production \cite{munters_towards_2018}. This was also confirmed in wind tunnel experiments and further simulations by Frederik et al. \cite{frederik_periodic_2020}. Frederik et al. used a oscillating pitch angle to steer the wake in a helical motion, also recording increases in power production in a setup of two turbines by $7.5$ percent \cite{frederik_helix_2020}. \\
Recently methods of machine learning have been applied in the more general area of active flow control. One such method is reinforcement learning (RL). RL has been used in a vast range of applications, such as playing Go and Chess \cite{silver_general_2018} or controlling a Mars lander  \cite{gaudet_deep_2020}. In active flow control the first application was by Rabault to reduce drag in a von Kármán vortex street \cite{rabault_artificial_2019}. Furthermore, it was used by Belus et al. to stabilize a thin fluid film \cite{belus_exploiting_2019}. As promising as these results are, it has to be noted that the problems tackled are laminar and do not show the highly complex nonlinear behaviour of turbulent flows. RL was developed in analogy to \\
A critical point when combining fluid simulations with RL is the computational cost of fluid simulations and the large number of timesteps required for RL. The Lattice Boltzmann Method has shown great potential to lower the computational cost of fluid simulations \cite{lohner_towards_2019}. It was also recently used for wind farm simulations by Asmuth et al. \cite{asmuth_actuator_2019}.\\
In this work, reinforcement learning will be applied to maximize power production in an LBM-LES simulation of a small wind park. In the first chapter, the theoretical foundations for wind turbine control and simulation, as well as RL and LBM are layed and a more detailed look into already existing control strategies. In the second chapter, the implementation and setup of the simulations is explained. In the following chapter the results of the simulations will be presented and examined. Finally a conclusion and outlook into future developments is given.