% !TEX root = ../../Diploma.tex
\section{Previous Works}
\subsection{Wind Farm Control}
In \autoref{sec:WTC} the greedy control strategy for a single turbine was described. However, this control strategy does not take into consideration the effects of the wake on other turbines within a wind farm. Therefore more sophisticated strategies with the objective of maximizing the generated power of multiple turbines or a whole wind farm have been proposed. They can be divided into two main categories, axial induction control and wake redirection control \cite{boersma_tutorial_2017}.
Axial induction control tries to lower the power intake of the first turbine, so that the wind speed at the following turbines is higher. Wake redirection control aims at steering the wake away from the next turbine downstream. A fairly recent review of the vast amount of studies dedicated to this topic can be found in \cite{kheirabadi_quantitative_2019}. \\
Overall, it shows that static axial induction control is able to increase total power, in LES-simulations usually around $\SI{5}{}$ percent. However, the magnitude of the increase depends on the simulation method and flow conditions. Aerodynamic phenomena not captured by BEM-like models can significantly decrease the generated power. For example, an increase in turbulence intensity also leads to a decrease in power, which is not accounted for by BEM-like models. This highlights the importance of LES simulations for studies on control.
Compared to the static approaches, dynamic approaches showed to be more promising. Based on a receding-horizon optimal control, Goit and Meyers \cite{goit_optimal_2015} were able to report an increase in power of $\SI{16}{}$ percent. However, this approach requires knowledge of the full flow field as well as adjoint simulations and thus not applicable to control of a real-world park. Based on these results, a simplified control strategy based on sinusoidal variation of the induction was proposed by Munters and Meyers \cite{munters_towards_2018}. This approach was further explored by Frederik et. al \cite{frederik_helix_2020}, leading to the development of the helix approach. They superimposed two sinusoidal variations of the pitch angle, one with the rotational frequency of the rotor, one with an arbitrary excitation frequency. This results in sinusoidal moments exerted on the wake in tilt and yaw direction. Due to these moments, the wake center moves in a helical motion, which gives this approach its name. They could report an increase in power of up to $\SI{7.5}{}$ percent. These results prove the theoretical potential for power increase by dynamic axial induction control and that simple control strategies can achieve considerable gains. \\
Static and dynamic wake redirection have also been explored, and the review in \cite{kheirabadi_quantitative_2019} concludes that it shows an even greater potential for improving power. However, this work will only focus on induction control.
\subsection{Machine Learning in Active Flow Control}
Formulating control strategies for active flow is inherently difficult, due to the non-linear nature of fluid-flow. This motivates the interest in methods of machine learning, since it has been shown in other areas that these methods can develop new strategies and deal with large state spaces, most famously in games such as Go \cite{silver_mastering_2017}, but also control of mars landers \cite{gaudet_deep_2020}. Recently, some studies applying reinforcement learning to active flow control have been conducted. A review of some of them can be found in \cite{garnier_review_2019}. The work by Verma et al. focussed on collectively swimming fishes and employed Q-learning, in which the action-value function is approximated by a neural network \cite{verma_efficient_2018}. Rabault et al. were the first ones to apply policy gradient methods. They used it to minimize the drag on a two-dimensional von-K\'arm\'an vortex street via jets \cite{rabault_deep_2018}. It showed the applicability of these methods to active flow control. In subsequent studies, which focussed on similar problems, i.e. two-dimensional laminar flow, more aspects of the application of DRL to flow control were studied. The use of parallel environments to reduce the wall time was proposed in \cite{rabault_accelerating_2019}. In \cite{belus_exploiting_2019}, policy gradient methods were successfully applied to control of a one-dimensional, unstable falling liquid film. While these studies showed promising results, the complexity of the controlled flows was still limited in comparison to a fully turbulent three-dimensional LES simulation.
