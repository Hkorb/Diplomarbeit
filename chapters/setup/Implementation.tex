\section{Implementation}
\subsection{Basic Implementation Strategy}
In this work the performance of two controllers in two simulation environments is studied. As a baseline case a greedy controller according to the description given above is implemented. This is compared to a controller that is governed by an RL-agent. They are compared in a one dimensional BEM model of a turbine, which is mainly used for rapid development, and an LBM-ALM environment with multiple turbines. \\
To provide a layer of abstraction between simulation environments and controllers, the so called visitors were introduced. Each turbine and velocity probe is represented by an instance of a visitor. It is provided with input by the simulation environments such as $M_{aero}$ or the velocity, but can also set controllable quantities such as $M_{gen}$. This allows for an easy recombination of simulation environments and controllers. \\
In contrast to most other applications of machine learning, in this case the main program is not the one governing the machine learning, but rather the simulation environment. This is due to the fact that the LBM-ALM simulation environment already existed prior to this work and it was expected to be simpler to design the RL-controller so that it could be called by the simulation environment, rather than breaking up the already existing code. Furthermore the LBM-ALM consumes the vast amount of computational time, so any potential for optimization in this part should be used. However, this approach also created some difficulties, especially regarding the concurrency of events and scope of objects, many of which were solved by using techniques of object oriented programming.
\subsection{RL-Controller}
The RL-controller relies on the library TF-Agents \cite{guadarrama_tf-agents_2018}, which implements many RL algorithms and is based on the Python API of TensorFlow \cite{abadi_tensorflow_2015}. The controller implements an MDP, with an environment, an agent and also governs the interaction between them. The frequency of interactions is not related to the size of the timestep of the simulation environment, since the relevant time scales are not necessarily connected \cite{rabault_deep_2018-1}. \\
An instance of the class \texttt{PPOAgent} represents the agent and contains the methods to calculate actions based on the observations and to train the agent. It is based on the ppo-algorithm explained above. The actor network consists of three layers, of which the first two layers are either fully connected lstm cells or regular feed forward layers. The activation function of these layers is $\tanh$. The width of these layers is adjustable. The last layer is a feed forward layer of $\mathrm{softplus}$ nodes. The value network is a three layered feed forward network with a $\mathrm{softplus}$ activation. \\
The interaction with the visitors is governed by an instance of the class \texttt{TurbineEnvironment}.The action provided by the agent is smoothed with an exponential filter to make it continuous. The decay rate $\alpha$ is chosen according to \eqref{eq:alpha}, with a forget ratio $FR$ of \SI{0.99}{}. $N_{t,A}$ is the number of time steps in the simulation in between actions of the network. The observations are also filtered exponentially, with the same rate as the action and can include multiple past timesteps in addition to the current timestep. If the environment reaches a terminal state, because a rotor turns too slow or too fast, the environment is controlled by a greedy controller, until it is in a stable state again. This was implemented since a reinitialization of the LBM-ALM simulation environment would be very costly. To reduce wall time, multiple environments can be run at the same time, each represented by a single instance of TurbineEnvironment. Therefore, all the TurbineEnvironments are wrapped in a single instance of a \texttt{ParallelTurbineEnvironment}. \\
\begin{align}
	\alpha &= FR^{1/N_{t,A}} \label{eq:alpha}\\
	x_t &= x_{t-1} + \alpha(\hat{x_t} - x_{t-1})
\end{align}
\subsection{Greedy Controller}
The greedy controller is an implementation of the baseline generator-torque controller given in \cite{jonkman_definition_2009}.
\subsection{LBM-ALM Environment}
The LBM-ALM environment is based on the work of Asmuth et al. \cite{asmuth_actuator_2019}. The actuator line model is implemented in elbe, a cumulant LBM code \cite{jansen_validation_2015}. For this work the code was extended to include a second order accurate refinement scheme according to Sch√∂nherr et al. \cite{schonherr_towards_2015}, for further information the reader is referred to \ref{app:refinement}. Multiple independent domains can be instantiated in one call to the main function, with creating only one instance of the controller, allowing for a significant reduction in wall time \cite{rabault_accelerating_2019-1}. A sequence diagramm of a timestep is given in \ref{fig:timestep} to demonstrate the interactions between elbe and the controller and visitors. The inlet is a uniform inflow, that can be superimposed with fluctuations of a Mann box \cite{mann_wind_1998}. The outlet uses a sponge layer, as described in section \ref{sec:LBM}.
\begin{figure}
	\centering
	\begin{sequencediagram}
		\newthread{elbe}{Elbe}{}
		\newinst{alm0}{ALM0:ActuatorLine}{}
		\newinst{turb0}{Turbine0:Turbine}{}
		\newinst{probe}{Probe0:Probe}{}
		\newinst{ctrl}{Controller:ANNController}
		
		\begin{callself}{elbe}{doTimestep()}{}
			\begin{call}{elbe}{visit()}{alm0}{}
				\begin{call}{alm0}{getState()}{turb0}{$\omega, \Theta$}\end{call}
				\begin{callself}{alm0}{calcTorque()}{$M_{aero}$}\end{callself}
				\begin{call}{alm0}{setTorque($M_{aero}$)}{turb0}{}\end{call}
			\end{call}
			\begin{call}{elbe}{visit()}{probe}{}
				\begin{callself}{probe}{setVelocity()}{}\end{callself}
			\end{call}
			\begin{call}{elbe}{visit()}{ctrl}{}
				\begin{callself}{ctrl}{update()}{}
					\begin{call}{ctrl}{update($M_{gen}$)}{turb0}{}
						\begin{callself}{turb0}{updateOmega()}{$\omega$}\end{callself}
						\begin{callself}{turb0}{updateAzimuth()}{$\Theta$}\end{callself}
					\end{call}
				\end{callself}
			\end{call}
		\end{callself}
	\end{sequencediagram}
	\caption{UML sequence diagram of simulation timestep.}
	\label{fig:timestep}
\end{figure}
\subsection{Fast Implimentation of a BEM Environment}
To provide the physical inputs of a one-dimensional model of the flow field and the turbine a steady state BEM-code for the computation of $C_t$ and $C_n$ was implemented. To minimize computational time, a table of 4000 values of $M_{aero}$ are precomputed and is then linearly interpolated. The fluid field is composed of a base velocity and an optionally superimposed turbulent fluctuation, which is computed by the synthetic turbulence generator TuGen \cite{gilling_tugen_2009}. The base velocity can also be varying in time, either by defining a sine wave or by regularly sampling a random velocity within a given interval. The interaction of the BEM environment with the coupling mechanism is designed to be as similar as possible to the interaction between elbe and the controller.

