% Encoding: UTF-8

@Book{Duriez2017,
  author    = {Duriez, Thomas and Brunton, Steven L and Noack, Bernd R},
  publisher = {Springer},
  title     = {Machine Learning Control-Taming Nonlinear Dynamics and Turbulence},
  year      = {2017},
  file      = {:2017_Book_MachineLearningControlTamingNo.pdf:PDF},
  groups    = {henry:6},
}

@Article{Rabault2018,
  author      = {Jean Rabault and Miroslav Kuchta and Atle Jensen and Ulysse Reglade and Nicolas Cerardi},
  title       = {Artificial Neural Networks trained through Deep Reinforcement Learning discover control strategies for active flow control},
  abstract    = {We present the first application of an Artificial Neural Network trained through a Deep Reinforcement Learning agent to perform active flow control. It is shown that, in a 2D simulation of the Karman vortex street at moderate Reynolds number (Re = 100), our Artificial Neural Network is able to learn an active control strategy from experimenting with the mass flow rates of two jets on the sides of a cylinder. By interacting with the unsteady wake, the Artificial Neural Network successfully stabilizes the vortex alley and reduces drag by about 8%. This is performed while using small mass flow rates for the actuation, on the order of 0.5% of the mass flow rate intersecting the cylinder cross section once a new pseudo-periodic shedding regime is found. This opens the way to a new class of methods for performing active flow control.},
  date        = {2018-08-23},
  doi         = {10.1017/jfm.2019.62},
  eprint      = {1808.07664v5},
  eprintclass = {physics.flu-dyn},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.07664v5:PDF},
  keywords    = {physics.flu-dyn},
}

@Article{Rabault2019,
  author      = {Jean Rabault and Alexander Kuhnle},
  title       = {Accelerating Deep Reinforcement Learning strategies of Flow Control through a multi-environment approach},
  abstract    = {Deep Reinforcement Learning (DRL) has recently been proposed as a methodology to discover complex Active Flow Control (AFC) strategies [Rabault, J., Kuchta, M., Jensen, A., Reglade, U., \& Cerardi, N. (2019): "Artificial neural networks trained through deep reinforcement learning discover control strategies for active flow control", Journal of Fluid Mechanics, 865, 281-302]. However, while promising results were obtained on a simple 2D benchmark flow at a moderate Reynolds number, considerable speedups will be required to investigate more challenging flow configurations. In the case of DRL trained with Computational Fluid Dynamics (CFD) data, it was found that the CFD part, rather than training the Artificial Neural Network, was the limiting factor for speed of execution. Therefore, speedups should be obtained through a combination of two approaches. The first one, which is well documented in the literature, is to parallelize the numerical simulation itself. The second one is to adapt the DRL algorithm for parallelization. Here, a simple strategy is to use several independent simulations running in parallel to collect experiences faster. In the present work, we discuss this solution for parallelization. We illustrate that perfect speedups can be obtained up to the batch size of the DRL agent, and slightly suboptimal scaling still takes place for an even larger number of simulations. This is, therefore, an important step towards enabling the study of more sophisticated Fluid Mechanics problems through DRL.},
  date        = {2019-06-25},
  doi         = {10.1063/1.5116415},
  eprint      = {1906.10382v3},
  eprintclass = {physics.comp-ph},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1906.10382v3:PDF},
  keywords    = {physics.comp-ph},
}

@Article{Rabault2018a,
  author      = {Jean Rabault and Ulysse Reglade and Nicolas Cerardi and Miroslav Kuchta and Atle Jensen},
  title       = {Deep Reinforcement Learning achieves flow control of the 2D Karman Vortex Street},
  abstract    = {The Karman Vortex Street has been investigated for over a century and offers a reference case for investigation of flow stability and control of high dimensionality, non-linear systems. Active flow control, while of considerable interest from a theoretical point of view and for industrial applications, has remained inaccessible due to the difficulty in finding successful control strategies. Here we show that Deep Reinforcement Learning can achieve a stable active control of the Karman vortex street behind a two-dimensional cylinder. Our results show that Deep Reinforcement Learning can be used to design active flow controls and is a promising tool to study high dimensionality, non-linear, time dependent dynamic systems present in a wide range of scientific problems.},
  date        = {2018-08-31},
  eprint      = {1808.10754v1},
  eprintclass = {physics.flu-dyn},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.10754v1:PDF},
  keywords    = {physics.flu-dyn},
}

@Article{Asmuth2019,
  author    = {Henrik Asmuth and Hugo Olivares-Espinosa and Karl Nilsson and Stefan Ivanell},
  journal   = {Journal of Physics: Conference Series},
  title     = {The Actuator Line Model in Lattice Boltzmann Frameworks: Numerical Sensitivity and Computational Performance},
  year      = {2019},
  month     = {jul},
  pages     = {012022},
  volume    = {1256},
  doi       = {10.1088/1742-6596/1256/1/012022},
  publisher = {{IOP} Publishing},
}

@Article{Asmuth2019a,
  author    = {Henrik Asmuth and Hugo Olivares-Espinosa and Stefan Ivanell},
  title     = {Actuator Line Simulations of Wind Turbine Wakes Using the Lattice Boltzmann Method},
  year      = {2019},
  month     = {dec},
  doi       = {10.5194/wes-2019-94},
  publisher = {Copernicus {GmbH}},
}

@Article{Ciri2017,
  author    = {Umberto Ciri and Mario Rotea and Christian Santoni and Stefano Leonardi},
  journal   = {Wind Energy},
  title     = {Large-eddy simulations with extremum-seeking control for individual wind turbine power optimization},
  year      = {2017},
  month     = {may},
  number    = {9},
  pages     = {1617--1634},
  volume    = {20},
  doi       = {10.1002/we.2112},
  publisher = {Wiley},
}

@Periodical{Fredrich2020,
  title    = {Windrad sucht Standort},
  year     = {2020},
  editor   = {Benjamin Fredrich},
  language = {german},
  month    = {01},
  series   = {Katapult - Magazin},
  volume   = {16},
}

@Article{Verma2018,
  author    = {Siddhartha Verma and Guido Novati and Petros Koumoutsakos},
  journal   = {Proceedings of the National Academy of Sciences},
  title     = {Efficient collective swimming by harnessing vortices through deep reinforcement learning},
  year      = {2018},
  month     = {may},
  number    = {23},
  pages     = {5849--5854},
  volume    = {115},
  doi       = {10.1073/pnas.1800923115},
  publisher = {Proceedings of the National Academy of Sciences},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:henry:6\;2\;1\;\;\;\;;
}
